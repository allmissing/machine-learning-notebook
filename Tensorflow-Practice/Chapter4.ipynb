{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Chapter4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 神经网络的进一步优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 调整学习率——指数衰减法：tf.train.exponential_decay函数\n",
    "\n",
    "1）等价于：decayed_learning_rate = learning_rate * decay_rate ^(global_step/decay_steps)\n",
    "\n",
    "2）参数：staircase\n",
    "\n",
    "staircase = False : 连续指数衰减学习率，不同的训练数据有不同的学习率\n",
    "\n",
    "staircase = True : 阶梯状学习率（global_step/decay_step会被转化为整数），在这样的设置下，decay_steps通常代表了完整的使用一遍训练数据所需要的迭代轮数。这个迭代轮数也就是总训练样本数除以一盒batch中的训练样本数。这种设置的常用场景是每完整地过完一遍训练数据，学习率就减少一次。这可以使得训练数据集中的所有数据对模型训练有相等的作用。\n",
    "\n",
    "3）tf.train.exponential_decay使用方法：\n",
    "\n",
    "tf.train.exponential_decay（初始学习率, global_step, 每训练多少轮学习率衰减, 衰减系数, staircase）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0)\n",
    "\n",
    "#通过exponential_decay函数生成学习率\n",
    "learning_rate = tf.train.exponential_decay(0.1, global_step, 100, 0.96, staircase = True)\n",
    "\n",
    "#使用指数衰减的学习率，在minimize函数中传入global_step将自动更新\n",
    "learning_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(...my loss..., global_step = global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 过拟合问题——正则化\n",
    "\n",
    "1）l2正则化——tf.contrib.layers.l2_regularizer / l1_regularizer\n",
    "\n",
    "带l2正则化的顺势函数定义方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([2,1], stddev = 1, seed = 1))\n",
    "y = tf.matmul(x, w)\n",
    "\n",
    "loss = tf.reduce_mean(tf.squre(y_- y)) + tf.contrib.layers.l2_regularizer(lambda)(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tf.contrib.layers.l2_regularizer / l1_regularizer的使用方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.constant([[1, -2],[-3, 4]])\n",
    "with tf.Session() as sess:\n",
    "    #输出为（|1|+|-2|+|-3|+|4|）*0.5 = 5，其中0.5是正则化项的权重\n",
    "    print(sess.run(tf.contrib.layerss.l1_regularizer(.5)(weights)))\n",
    "    #输出为（1^2+（-2）^2+(-3)^2+4^2）/2*0.5=7.5\n",
    "    print(sess.run(tf.contrib.layers.l2_regularizer(.5)(weights)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 在测试数据上更健壮的一种方法——滑动平均模型：tf.train.ExponentialMovingAverage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1 = tf.Variable(0,dtype = tf.float32)\n",
    "#这里step变量模拟神经网络中迭代的轮数，可以用于动态控制衰减率\n",
    "step = tf.Variable(0, trainable = False)\n",
    "\n",
    "#定义一个滑动平均的类（class）.初始化时给定了衰减率（0.99）和控制衰减率的变量step\n",
    "ema = tf.train.ExponentialMovingAverage(0.99, step)\n",
    "#\n",
    "maintain_average_op = ema.apply([v1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #初始化所有变量\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    #通过ema.average(v1)获取滑动平均之后变量的取值。在初始化之后变量v1的值和v1的值和v1的滑动平均都为0\n",
    "    print sess.run([v1, ema.average(v1)])\n",
    "    sess.run(tf.assign(v1,5))\n",
    "    sess.run(maintain_average_op)\n",
    "    print sess,run([v1,ema.average(v1)])\n",
    "    \n",
    "    #更新step的值为10000\n",
    "    sess.run(tf.assign(step,10000))\n",
    "    sess.run(tf.assign(v1,10))\n",
    "    sess.run(maintain_average_op)\n",
    "    print sess.run([v1,ema.average(v1)])\n",
    "    \n",
    "    sess.run(maintain_averages_op)\n",
    "    print sess.run([v1,ema.average(v1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
